"""Embedding service that generates deterministic vector representations of text.

This module provides a service for creating consistent vector embeddings by hashing text
content. The embeddings are used for vector similarity search and storage in the memory
system. Key features:

- Deterministic: Same input text always produces the same embedding vector
- Consistent dimensionality: All embeddings have the same configurable dimension
- Efficient caching: LRU cache for frequently accessed text
- Error handling: Returns zero vectors on failure, with detailed logging
- Thread-safe: Can be safely used in concurrent contexts

The service uses SHA-256 hashing to map text to float values between -1 and 1,
creating embeddings suitable for similarity comparisons."""

import logging
import hashlib
from typing import List, Union, Optional

logger = logging.getLogger(__name__)

class EmbeddingService:
    """Service for creating deterministic embeddings using SHA-256 hashing.
    
    This service generates consistent vector embeddings by hashing input text and mapping
    the hash bytes to float values between -1 and 1. The service maintains an LRU cache
    to avoid recomputing embeddings for frequently accessed text.
    
    Implementation Details:
    - Uses SHA-256 to hash input text to ensure deterministic output
    - Maps hash bytes to float values in range [-1.0, 1.0] for vector components
    - Supports both single text and batch text inputs
    - Implements async methods for concurrent usage
    - Thread-safe caching implementation
    
    Error Handling:
    - Returns zero vector(s) on embedding creation failure
    - Raises ValueError if dimension is not set
    - Logs errors through the logging system
    - Gracefully handles encoding errors
    
    Cache Behavior:
    - Maintains fixed-size LRU cache (default 1000 entries)
    - Automatically evicts oldest entries when cache is full
    - Cache hits avoid recomputing embeddings
    - Separate cache entries for each unique text input
    
    Usage:
    >>> service = EmbeddingService(cache_size=1000, dimension=768)
    >>> embedding = await service.create_embedding("example text")
    >>> embeddings = await service.create_embedding(["text1", "text2"])"""
    
    def __init__(
        self,
        cache_size: int = 1000,
        dimension: int = 768,
        model: str = "text-embedding-nomic-embed-text-v1.5@f16"
    ):
        """Initialize embedding service with configurable cache and dimension.
        
        Args:
            cache_size: Maximum number of embeddings to cache. When cache reaches this size,
                      oldest entries are evicted first. Defaults to 1000.
            dimension: Number of dimensions for generated embedding vectors. This value is
                      fixed after initialization and used for all embeddings. Higher values
                      provide more detailed representations but use more memory. 
                      Defaults to 768 to match common embedding models.
            model: Name of the embedding model to use. Defaults to nomic-embed-text.
        """
        self._dimension = dimension  # Set default dimension
        self._cache = {}  # Simple cache for embeddings
        self._cache_size = cache_size
        self.model = model  # Store model name
        logger.info("Embedding service initialized")
    
    @property
    async def dimension(self) -> int:
        """Get the embedding dimension used for vector generation.
        
        The dimension property returns the fixed dimension size used for all embeddings
        generated by this service. This value is set during initialization and remains
        constant throughout the service's lifetime.
        
        Returns:
            int: Number of dimensions in the embedding vectors. This determines the size
                of all generated embedding vectors. A larger dimension allows for more
                detailed representations but requires more memory.
                
        Error Handling:
            - If dimension is not set (None), logs an error through the logging system
            - Returns None in error case to allow graceful handling by caller
            - Subsequent embedding creation will fail with ValueError if dimension is None
            
        Note:
            The dimension cannot be changed after initialization. Create a new service
            instance if a different dimension is needed.
        """
        if self._dimension is None:
            # Dimension not set
            logger.error("Dimension not set")
        return self._dimension
            
    def _get_from_cache(self, text: str) -> Optional[List[float]]:
        """Get embedding from cache if available.
        
        Args:
            text: Text string to look up in cache
            
        Returns:
            Optional[List[float]]: Cached embedding vector if found, None if not in cache
        """
        return self._cache.get(text)

    def _add_to_cache(self, text: str, embedding: List[float]):
        """Add embedding to cache, removing oldest entry if at capacity.
        
        Args:
            text: Text string to use as cache key
            embedding: Embedding vector to store in cache
            
        Note:
            If cache is at capacity (self._cache_size), the oldest entry will be
            removed before adding the new one.
        """
        if len(self._cache) >= self._cache_size:
            # Remove oldest item
            oldest_key = next(iter(self._cache))
            del self._cache[oldest_key]
        self._cache[text] = embedding

    async def create_embedding(self, text: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """Create hash-based embeddings for text with caching.
        
        Args:
            text: Single text string or list of text strings to embed. For batch processing,
                 pass a list of strings to embed them all at once.
            
        Returns:
            List[float] or List[List[float]]: 
                - For single text input (str): Returns a single embedding vector as List[float]
                - For batch input (List[str]): Returns List[List[float]] containing an embedding
                  vector for each input text in the same order
                - Each vector has dimension specified by self._dimension
                - Uses cached embeddings when available for better performance
                
        Raises:
            ValueError: If dimension is not set (None)
            
        Error Handling:
            - Returns zero vector(s) on embedding creation failure
            - Logs detailed error information through logging system
            - Handles encoding errors gracefully
            - Maintains cache integrity even after errors
            
        Cache Behavior:
            - Checks cache before computing new embeddings
            - Updates cache with new embeddings after computation
            - Handles cache eviction when at capacity
            - Thread-safe cache operations
        """
        try:
            # Check cache for single text
            if isinstance(text, str):
                cached = self._get_from_cache(text)
                if cached is not None:
                    logger.debug("Using cached embedding")
                    return cached
                texts = [text]
            else:
                # For list input, check cache for each text
                texts = []
                cached_embeddings = []
                need_embedding = False
                for t in text:
                    cached = self._get_from_cache(t)
                    if cached is not None:
                        cached_embeddings.append(cached)
                    else:
                        need_embedding = True
                        texts.append(t)
                        cached_embeddings.append(None)
                
                # If all embeddings were cached, return them
                if not need_embedding:
                    logger.debug("Using all cached embeddings")
                    return cached_embeddings
                
            # Use hash-based embeddings
            logger.debug("Creating hash-based embeddings")
            if isinstance(text, str):
                # Create deterministic embedding based on text hash
                hash_obj = hashlib.sha256(text.encode())
                hash_bytes = hash_obj.digest()
                # Use hash bytes to create float values between -1 and 1
                embedding = []
                for i in range(self._dimension):
                    byte_val = hash_bytes[i % len(hash_bytes)]
                    val = (byte_val / 128.0) - 1.0
                    embedding.append(val)
                self._add_to_cache(text, embedding)
                return embedding
            else:
                # Handle list of texts
                embeddings = []
                for t in texts:
                    hash_obj = hashlib.sha256(t.encode())
                    hash_bytes = hash_obj.digest()
                    embedding = []
                    for i in range(self._dimension):
                        byte_val = hash_bytes[i % len(hash_bytes)]
                        val = (byte_val / 128.0) - 1.0
                        embedding.append(val)
                    embeddings.append(embedding)
                    self._add_to_cache(t, embedding)
                return embeddings
            
        except Exception as e:
            logger.error(f"Failed to create embedding: {str(e)}")
            if self._dimension is None:
                raise ValueError("Cannot create embedding: dimension not yet determined") 
            # Return zero vector on error
            zero_vector = [0.0] * self._dimension
            return zero_vector if isinstance(text, str) else [zero_vector]
