# NIA Core Agent Testing

This notebook provides interactive testing of core agents to verify their functionality and interactions.

## Setup Requirements

1. Neo4j Database:
   * Ensure Neo4j is running locally
   * Default URI: bolt://localhost:7687
   * Default credentials: neo4j/password
   * Run `docker-compose up -d neo4j` from project root

2. Python Environment:
   * Python 3.8+
   * Install requirements: `pip install -r requirements.txt`
   * Install Jupyter: `pip install jupyter`

3. Running the Notebook:
   * Start Jupyter: `jupyter notebook`
   * Navigate to this notebook
   * Run cells sequentially to test each component

4. Expected Behavior:
   * Memory operations should connect to Neo4j
   * Agents should process inputs and coordinate
   * Domain separation should work correctly
   * Error handling should catch issues

Note: If you encounter connection errors, verify Neo4j is running and accessible.

## 1. Environment Setup

```python
import sys
sys.path.append('..')

from src.nia.nova.core.implementation import (
    TinyPerson,
    TwoLayerMemorySystem,
    Nova,
    ConsolidationPattern,
    TinyTroupePattern,
    EmergentTaskDetector,
    TaskApprovalSystem,
    CoordinationAgent,
    ConversationLogger
)

# Import core agents
from src.nia.agents.specialized.parsing_agent import ParsingAgent
from src.nia.agents.specialized.belief_agent import BeliefAgent
from src.nia.agents.specialized.emotion_agent import EmotionAgent
from src.nia.agents.specialized.reflection_agent import ReflectionAgent
from src.nia.agents.specialized.desire_agent import DesireAgent
from src.nia.agents.specialized.orchestration_agent import OrchestrationAgent

# Initialize memory system
memory = TwoLayerMemorySystem(
    neo4j_uri="bolt://localhost:7687",
    neo4j_user="neo4j",
    neo4j_password="password"
)

# Initialize logger for readable output
logger = ConversationLogger()
```

## 2. Basic Agent Dialogue

```python
# Initialize agents with readable names
parsing_agent = ParsingAgent(name="Parser")
belief_agent = BeliefAgent(name="Believer")
emotion_agent = EmotionAgent(name="Empath")
reflection_agent = ReflectionAgent(name="Reflector")
desire_agent = DesireAgent(name="Motivator")

# Test dialogue
async def test_basic_dialogue():
    logger.log("Starting basic agent dialogue test...")
    
    input_text = "We need to improve our documentation based on user feedback."
    
    # Parser processes input
    logger.log(f"\nParser receiving: '{input_text}'")
    parsed = await parsing_agent.parse_text(input_text)
    logger.log(f"Parser extracted: {parsed}")
    
    # Believer forms beliefs
    logger.log("\nBeliever analyzing evidence...")
    beliefs = await belief_agent.process_evidence(parsed)
    logger.log(f"Believer formed beliefs: {beliefs}")
    
    # Empath processes emotions
    logger.log("\nEmpath analyzing emotional context...")
    emotions = await emotion_agent.process_input(parsed)
    logger.log(f"Empath detected emotions: {emotions}")
    
    # Reflector considers implications
    logger.log("\nReflector analyzing situation...")
    reflection = await reflection_agent.reflect({
        "input": parsed,
        "beliefs": beliefs,
        "emotions": emotions
    })
    logger.log(f"Reflector's insights: {reflection}")
    
    # Motivator forms desires
    logger.log("\nMotivator determining priorities...")
    desires = await desire_agent.process_motivation(
        context=reflection,
        priority="high"
    )
    logger.log(f"Motivator's recommendations: {desires}")

await test_basic_dialogue()
```

## 3. Swarm Coordination Test

```python
# Initialize swarm components
orchestration_agent = OrchestrationAgent(
    name="Orchestrator",
    memory_system=memory,
    domain="professional"
)

async def test_swarm_coordination():
    logger.log("Starting swarm coordination test...")
    
    # Configure swarm
    swarm_config = {
        "architecture": "hierarchical",
        "type": "MajorityVoting",
        "roles": {
            "coordinator": ["Parser", "Orchestrator"],
            "worker": ["Believer", "Empath", "Reflector", "Motivator"]
        }
    }
    
    logger.log("\nOrchestrator configuring swarm...")
    await orchestration_agent.configure_swarm(swarm_config)
    logger.log(f"Swarm configured: {swarm_config}")
    
    # Test resource allocation with emotions
    logger.log("\nTesting emotion-based resource allocation...")
    orchestration_agent.emotions.update({
        "orchestration_state": "highly_focused",
        "resource_state": "optimal",
        "execution_state": "running"
    })
    logger.log(f"Orchestrator emotional state: {orchestration_agent.emotions}")
    
    resources = {
        "cpu": {
            "type": "compute",
            "capacity": 100.0,
            "utilization": 75.0,
            "assigned_to": ["Believer", "Empath"]
        }
    }
    
    await orchestration_agent._update_resource_allocations(resources)
    logger.log(f"Resource allocation result: {orchestration_agent.resource_allocations}")
    
    # Test pattern learning
    logger.log("\nTesting pattern-based learning...")
    await orchestration_agent._store_allocation_pattern(
        "cpu",
        {
            "type": "compute",
            "utilization": 0.9,
            "assigned_to": ["Reflector", "Motivator"]
        }
    )
    
    patterns = await orchestration_agent._get_allocation_patterns()
    logger.log(f"Learned patterns: {patterns}")
    
    # Test full swarm operation
    logger.log("\nTesting full swarm operation...")
    content = {
        "flow_id": "documentation_improvement",
        "input": "Update API documentation with more examples",
        "resources": {
            "memory": {"type": "ram", "capacity": 16.0},
            "cpu": {"type": "compute", "capacity": 100.0}
        },
        "agents": {
            "Parser": {"task": "Extract requirements"},
            "Believer": {"task": "Validate importance"},
            "Empath": {"task": "Assess urgency"},
            "Reflector": {"task": "Plan approach"},
            "Motivator": {"task": "Set priorities"}
        }
    }
    
    result = await orchestration_agent.orchestrate_and_store(content, "sequential")
    logger.log("\nFull swarm operation completed:")
    logger.log(f"- Flow state: {result.flow_state}")
    logger.log(f"- Resource state: {result.resource_state}")
    logger.log(f"- Agent states: {result.agent_states}")
    logger.log(f"- Decisions made: {result.decisions}")

await test_swarm_coordination()
```

## 4. Memory Integration Test

```python
async def test_memory_integration():
    logger.log("Starting memory integration test...")
    
    # Store swarm operation results
    logger.log("\nStoring operation in memory...")
    await memory.store_with_domain(
        content={
            "type": "swarm_operation",
            "flow_id": "documentation_improvement",
            "outcome": "success",
            "patterns_learned": 2,
            "resources_optimized": ["cpu", "memory"]
        },
        domain="professional"
    )
    
    # Query recent operations
    logger.log("\nQuerying recent operations...")
    results = await memory.query_by_domain(
        query="swarm_operation",
        domain="professional"
    )
    logger.log(f"Memory query results: {results}")
    
    # Test pattern retrieval
    logger.log("\nRetrieving learned patterns...")
    patterns = await orchestration_agent._get_allocation_patterns()
    logger.log(f"Retrieved patterns: {patterns}")
    
    # Test cross-operation learning
    logger.log("\nTesting pattern application to new operation...")
    similarity = orchestration_agent._calculate_pattern_similarity(
        patterns[0]["allocation"],
        {
            "type": "compute",
            "utilization": 0.85,
            "assigned_to": ["Parser", "Believer"]
        }
    )
    logger.log(f"Pattern similarity score: {similarity}")

await test_memory_integration()
```

## 5. Error Handling Test

```python
async def test_error_handling():
    logger.log("Starting error handling test...")
    
    try:
        logger.log("\nTesting invalid domain...")
        await orchestration_agent.orchestrate_and_store(
            {"type": "test"},
            "sequential",
            target_domain="invalid"
        )
    except ValueError as e:
        logger.log(f"Domain error caught: {e}")
    
    try:
        logger.log("\nTesting invalid swarm configuration...")
        await orchestration_agent.configure_swarm({
            "architecture": "invalid",
            "type": "unknown"
        })
    except ValueError as e:
        logger.log(f"Configuration error caught: {e}")
    
    try:
        logger.log("\nTesting resource overallocation...")
        await orchestration_agent._update_resource_allocations({
            "cpu": {
                "capacity": 100.0,
                "utilization": 150.0  # Over 100%
            }
        })
    except ValueError as e:
        logger.log(f"Resource error caught: {e}")

await test_error_handling()
```

## 6. Cleanup

```python
# Clean up resources
logger.log("Cleaning up resources...")
await memory.close()
logger.log("Memory connection closed")
logger.log("Testing complete!")
